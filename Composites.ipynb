{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60528c0d-4eb1-4ff3-a9b2-12746b8d4caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessieeastburn/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing GEE\n",
      "Successfully initialized\n",
      "geeViz package folder: /Users/jessieeastburn/Library/Python/3.9/lib/python/site-packages/geeViz\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#Example of how to get Landsat data using the getImagesLib and view outputs using the Python visualization tools\n",
    "#Acquires Landsat data and then adds them to the viewer\n",
    "####################################################################################################\n",
    "import os,sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "#Module imports\n",
    "import geeViz.getImagesLib as getImagesLib\n",
    "ee = getImagesLib.ee\n",
    "Map = getImagesLib.Map\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84b354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sf/r2b9cx3s6fl_d5hscrs0_44c0000gn/T/ipykernel_89656/2923351378.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#pip install geeViz\n",
    "#pip install geemap\n",
    "#import geeViz as Map\n",
    "import pandas as pd\n",
    "import time\n",
    "# Authenticate and initialize Earth Engine\n",
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e11b65fb-bbc4-47a1-b55b-7213cde20b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding layer: utka\n",
      "Starting webmap\n",
      "Using default refresh token for geeView\n",
      "Local web server at: http://localhost:1990/geeView/ already serving.\n",
      "cwd /Users/jessieeastburn/Library/CloudStorage/OneDrive-UniversityofUtah/URSA_Work/TS2/PJ_TimeSeries\n",
      "geeView URL: http://localhost:1990/geeView/?projectID=None&accessToken=ya29.a0AfB_byAS7h8QNxX3YVeAq-z3rAnDeOCmN1Z40GdBIQpSoG2XjT0gtVCrGOZsewQdLeXHHxdheDLKqYKi1Lb0RwmdCAFZqHCumYZy3TfKuo-XGmgZ2yicoMVKiOTpIgOBEu2euLjq3fTqHARXG0oWE-wk13SlHI97VqhDMAaCgYKAegSARISFQHGX2MiQb67P2wTTsQZdeRwvYdSjw0173\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"http://localhost:1990/geeView/?projectID=None&accessToken=ya29.a0AfB_byAS7h8QNxX3YVeAq-z3rAnDeOCmN1Z40GdBIQpSoG2XjT0gtVCrGOZsewQdLeXHHxdheDLKqYKi1Lb0RwmdCAFZqHCumYZy3TfKuo-XGmgZ2yicoMVKiOTpIgOBEu2euLjq3fTqHARXG0oWE-wk13SlHI97VqhDMAaCgYKAegSARISFQHGX2MiQb67P2wTTsQZdeRwvYdSjw0173\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1039aeee0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "::1 - - [20/Feb/2024 16:32:35] \"GET /geeView/?projectID=None&accessToken=ya29.a0AfB_byAS7h8QNxX3YVeAq-z3rAnDeOCmN1Z40GdBIQpSoG2XjT0gtVCrGOZsewQdLeXHHxdheDLKqYKi1Lb0RwmdCAFZqHCumYZy3TfKuo-XGmgZ2yicoMVKiOTpIgOBEu2euLjq3fTqHARXG0oWE-wk13SlHI97VqhDMAaCgYKAegSARISFQHGX2MiQb67P2wTTsQZdeRwvYdSjw0173 HTTP/1.1\" 200 -\n",
      "::1 - - [20/Feb/2024 16:32:35] \"GET /geeView/src/gee/gee-run/runGeeViz.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get utka polygon.\n",
    "studyArea = (\n",
    "    ee.FeatureCollection('projects/disco-glass-413820/assets/plot_min_bound_geom')\n",
    "    .filter(\"site_id == 'UOFU_UTKA'\")\n",
    "    .first()\n",
    "    .geometry()\n",
    ")\n",
    "\n",
    "Map.port = 1990\n",
    "Map.clearMap()\n",
    "\n",
    "studyArea = ee.Geometry.Polygon(\n",
    "            [[[-112.2647, 37.02876], \n",
    "              [-112.2647, 37.10894],\n",
    "              [-112.0867, 37.10894],\n",
    "              [-112.0867, 37.02876], \n",
    "              [-112.2647, 37.02876]]])\n",
    "Map.centerObject(studyArea, 11)\n",
    "Map.addLayer(studyArea, {'color': 'blue'}, 'utka')\n",
    "Map.view()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19772574-3a03-4187-8a12-ff5736b2c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "studyArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31f4879-0ecf-4fce-9e04-4c8cd948b044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Processed Landsat: \n",
      "Start date: Jan 01 2015 , End date: Dec 30 2020\n",
      "Applying scale factors for C2 L4 data\n",
      "Applying scale factors for C2 L5 data\n",
      "Applying scale factors for C2 L8 data\n",
      "Only including SLC On Landsat 7\n",
      "Applying scale factors for C2 L7 data\n",
      "Applying scale factors for C2 L9 data\n",
      "Applying Fmask Cloud Mask\n",
      "Applying Fmask Shadow Mask\n",
      "Adding layer: Default Params 2015 1-365\n",
      "Adding layer: Default Params 2016 1-365\n",
      "Adding layer: Default Params 2017 1-365\n",
      "Adding layer: Default Params 2018 1-365\n",
      "Adding layer: Default Params 2019 1-365\n",
      "Adding layer: Default Params 2020 1-365\n",
      "Adding layer: utka\n",
      "Starting webmap\n",
      "Using default refresh token for geeView\n",
      "Local web server at: http://localhost:1990/geeView/ already serving.\n",
      "cwd /Users/jessieeastburn/Library/CloudStorage/OneDrive-UniversityofUtah/URSA_Work/TS2/PJ_TimeSeries\n",
      "geeView URL: http://localhost:1990/geeView/?projectID=None&accessToken=ya29.a0AfB_byBpd0NUZCPiLkPV1kyamwmE_-WgzL8n4twK9Y4xm6aDmdYuyubOYj1_6z51aBH_6TM7ubckDD_eojwag8ShhCBYe9_4ekESLuLS3rQRJ3E_XLgIBHQOBIXZNXFNy1ULqyFdDmFzmkrvzTCSTUxbqywd1p4nlziQfAaCgYKARISARISFQHGX2MiKDCjGYe4eH4RhUKhkOIy0Q0173\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"http://localhost:1990/geeView/?projectID=None&accessToken=ya29.a0AfB_byBpd0NUZCPiLkPV1kyamwmE_-WgzL8n4twK9Y4xm6aDmdYuyubOYj1_6z51aBH_6TM7ubckDD_eojwag8ShhCBYe9_4ekESLuLS3rQRJ3E_XLgIBHQOBIXZNXFNy1ULqyFdDmFzmkrvzTCSTUxbqywd1p4nlziQfAaCgYKARISARISFQHGX2MiKDCjGYe4eH4RhUKhkOIy0Q0173\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x112df3d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "::1 - - [20/Feb/2024 16:34:41] \"GET /geeView/?projectID=None&accessToken=ya29.a0AfB_byBpd0NUZCPiLkPV1kyamwmE_-WgzL8n4twK9Y4xm6aDmdYuyubOYj1_6z51aBH_6TM7ubckDD_eojwag8ShhCBYe9_4ekESLuLS3rQRJ3E_XLgIBHQOBIXZNXFNy1ULqyFdDmFzmkrvzTCSTUxbqywd1p4nlziQfAaCgYKARISARISFQHGX2MiKDCjGYe4eH4RhUKhkOIy0Q0173 HTTP/1.1\" 200 -\n",
      "::1 - - [20/Feb/2024 16:34:41] \"GET /geeView/src/gee/gee-run/runGeeViz.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Specify study area: Study area\n",
    "# Can be a featureCollection, feature, or geometry\n",
    "#studyArea = ee.FeatureCollection('projects/lcms-292214/assets/R8/PR_USVI/Ancillary/prusvi_boundary_buff2mile').geometry().bounds()#testAreas['CA']\n",
    "\n",
    "# Update the startJulian and endJulian variables to indicate your seasonal \n",
    "# constraints. This supports wrapping for tropics and southern hemisphere.\n",
    "# If using wrapping and the majority of the days occur in the second year, the system:time_start will default \n",
    "# to June 1 of that year.Otherwise, all system:time_starts will default to June 1 of the given year\n",
    "# startJulian: Starting Julian date \n",
    "# endJulian: Ending Julian date\n",
    "startJulian = 1\n",
    "endJulian = 365\n",
    "\n",
    "# Specify start and end years for all analyses\n",
    "# More than a 3 year span should be provided for time series methods to work \n",
    "# well. If providing pre-computed stats for cloudScore and TDOM, this does not \n",
    "# matter\n",
    "startYear = 2015\n",
    "endYear = 2020\n",
    "\n",
    "#Call on master wrapper function to get Landat scenes and composites\n",
    "lsAndTs = getImagesLib.getLandsatWrapper(studyArea,startYear,endYear,startJulian,endJulian)\n",
    "\n",
    "\n",
    "#Separate into scenes and composites for subsequent analysis\n",
    "processedScenes = lsAndTs['processedScenes']\n",
    "processedComposites = lsAndTs['processedComposites']\n",
    "\n",
    "# Indicate what type of image is being added to speed up map service creation\n",
    "getImagesLib.vizParamsFalse['layerType']= 'geeImage';\n",
    "\n",
    "Map.clearMap()\n",
    "Map.port = 1990\n",
    "#Map.addLayer(processedComposites.select(['NDVI','NBR']),{'addToLegend':'false'},'Time Series (NBR and NDVI)',True)\n",
    "for year in range(startYear,endYear + 1 ):\n",
    "     t = processedComposites.filter(ee.Filter.calendarRange(year,year,'year')).mosaic()\n",
    "     Map.addLayer(t.float(),getImagesLib.vizParamsFalse,'Default Params {} {}-{}'.format(year,startJulian,endJulian),'True')\n",
    "#Map.centerObject(studyArea, 9)\n",
    "\n",
    "Map.centerObject(studyArea, 11)\n",
    "Map.addLayer(studyArea, {'color': 'blue'}, 'utka')\n",
    "\n",
    "Map.turnOnInspector()\n",
    "Map.view()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792fbaee-187d-42f8-a706-c0f0f0176224",
   "metadata": {},
   "outputs": [],
   "source": [
    "studyArea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c7a1f3-dc76-4edf-86ad-b0f06f5e93a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can access the parameters that were used through the properties of the returned collection\n",
    "print(processedComposites.toDictionary().getInfo())\n",
    "print(processedScenes.toDictionary().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abae13d-4ad4-4d8b-9c59-8a27b818be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since there are not that many images available in this area for these years, let's try adding Landsat 7\n",
    "includeSLCOffL7 = True\n",
    "#Call on master wrapper function to get Landat scenes and composites\n",
    "lsAndTs = getImagesLib.getLandsatWrapper(studyArea,startYear,endYear,startJulian,endJulian,includeSLCOffL7=includeSLCOffL7)\n",
    "\n",
    "#Separate into scenes and composites for subsequent analysis\n",
    "processedScenes = lsAndTs['processedScenes']\n",
    "processedComposites = lsAndTs['processedComposites']\n",
    "\n",
    "Map.clearMap()\n",
    "#Turn off layers from previous iteration\n",
    "Map.turnOffAllLayers()\n",
    "\n",
    "# Map.addLayer(processedComposites.select(['NDVI','NBR']),{'addToLegend':'false'},'Time Series (NBR and NDVI)',False)\n",
    "for year in range(startYear,endYear + 1 ):\n",
    "     t = processedComposites.filter(ee.Filter.calendarRange(year,year,'year')).mosaic()\n",
    "     Map.addLayer(t.float(),getImagesLib.vizParamsFalse,'L7 added {} {}-{}'.format(year,startJulian,endJulian),'True')\n",
    "\n",
    "\n",
    "Map.view()\n",
    "\n",
    "#You'll notice this helps fill in the holes, but introduces many cloud-related artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abf3af0-37b0-4b68-b121-e797b9259057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to improve the cloud masking. Fmask is used by default, but misses some clouds\n",
    "#We'll try the adding in the cloudScore method\n",
    "applyCloudScore = True\n",
    "\n",
    "#Call on master wrapper function to get Landat scenes and composites\n",
    "lsAndTs = getImagesLib.getLandsatWrapper(studyArea,startYear,endYear,startJulian,endJulian,includeSLCOffL7=includeSLCOffL7,applyCloudScore=applyCloudScore)\n",
    "\n",
    "\n",
    "#Separate into scenes and composites for subsequent analysis\n",
    "processedScenes = lsAndTs['processedScenes']\n",
    "processedComposites = lsAndTs['processedComposites']\n",
    "\n",
    "#clear map\n",
    "Map.clearMap()\n",
    "\n",
    "#Turn off layers from previous iteration\n",
    "Map.turnOffAllLayers()\n",
    "\n",
    "Map.addLayer(processedComposites.select(['NDVI','NBR']),{'addToLegend':'true'},'Time Series (NBR and NDVI)',True)\n",
    "for year in range(startYear,endYear + 1 ):\n",
    "     t = processedComposites.filter(ee.Filter.calendarRange(year,year,'year')).mosaic()\n",
    "     Map.addLayer(t.float(),getImagesLib.vizParamsFalse,'L7 and CloudScore added {} {}-{}'.format(year,startJulian,endJulian),'True')\n",
    "\n",
    "\n",
    "Map.view()\n",
    "\n",
    "#this cleans up the cloud masking a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa4e82-a585-4967-b975-7ba4829a7d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You'll still notice there are some dark areas likely due to cloud shadow masking omission\n",
    "#Fmasks's cloud shadow mask misses a lot typically. A temporal outlier method called the \n",
    "#Temporal Dark Outlier Mask (TDOM) works well with masking cloud shadows\n",
    "\n",
    "#We'll try the cloudScore method\n",
    "applyTDOM = True\n",
    "\n",
    "#Call on master wrapper function to get Landat scenes and composites\n",
    "#In order to identify dark outliers, we will extend the dates by 6 years to get a larger sample\n",
    "lsAndTs = getImagesLib.getLandsatWrapper(studyArea,startYear-3,endYear+3,startJulian,endJulian,includeSLCOffL7=includeSLCOffL7,applyCloudScore=applyCloudScore,applyTDOM=applyTDOM)\n",
    "\n",
    "\n",
    "#Separate into scenes and composites for subsequent analysis\n",
    "processedScenes = lsAndTs['processedScenes']\n",
    "processedComposites = lsAndTs['processedComposites']\n",
    "\n",
    "#Turn off layers from previous iteration\n",
    "Map.turnOffAllLayers()\n",
    "\n",
    "Map.addLayer(processedComposites.select(['NDVI','NBR']),{'addToLegend':'false'},'Time Series (NBR and NDVI)',True)\n",
    "for year in range(startYear,endYear + 1 ):\n",
    "     t = processedComposites.filter(ee.Filter.calendarRange(year,year,'year')).mosaic()\n",
    "     Map.addLayer(t.float(),getImagesLib.vizParamsFalse,'CloudScore and TDOM added {} {}-{}'.format(year,startJulian,endJulian),'True')\n",
    "\n",
    "\n",
    "Map.view()\n",
    "\n",
    "#You'll notice this cleans up the cloud masking a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc7c1e5-4452-4941-81c9-102123c1ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run get images, set parameters manually, and export\n",
    "lsAndTs = getImagesLib.getLandsatWrapper(\\\n",
    "\n",
    "    # Study area and time\n",
    "    studyArea = studyArea,\n",
    "    startYear = 2015,\n",
    "    endYear = 2020,\n",
    "    startJulian = 1,\n",
    "    endJulian = 365,\n",
    "\n",
    "    # Moving window options\n",
    "    timebuffer =  0,# If multi-year moving window is needed, use timebuffer > 0 (e.g. timebuffer = 1 will result in a 3 year moving window)\n",
    "    weights =  [1],# To compliment the timebuffer, set weights for each year of the moving window. This enables the center year to have more weight (e.g. [1,3,1] would weight the center year if timebuffer = 1 3x over the buffer years)\n",
    "\n",
    "    # Composite methods and input imagery\n",
    "    compositingMethod = 'medoid', # Specify median or medoid. Medoid allows for storing only the spectral and ancillary bands without indices\n",
    "    toaOrSR = 'SR', # It is advised to only use TOA when combining Landsat and Sentinel-2 since the Sentinel-2 SR data in GEE are terrain-corrected and Landsat are not\n",
    "    includeSLCOffL7 = False, # Whether to include Landsat 7 after May 2003. Scanline artifacts can be found in composites when True\n",
    "    defringeL5 = True, # Whether to get rid of fringe edges found mostly on Landsat 4 and 5\n",
    "    landsatCollectionVersion = 'C2', # To use Collection 1 or 2. Only use C1 if doing legacy work prior to 2022\n",
    "\n",
    "    # Cloud and shadow masking\n",
    "    # There will be a parameter for applying CloudScore+ to Sentinel-2 provided once it is available for all S2 data\n",
    "    applyCloudScore = True, # We use this since fMask struggles for cloud masking\n",
    "    applyTDOM = True, # We use TDOM for Landsat since the fMask cloud shadow masking method struggles a lot\n",
    "    applyFmaskCloudMask = True,\n",
    "    applyFmaskCloudShadowMask = True,\n",
    "    applyFmaskSnowMask = False,\n",
    "    cloudScoreThresh = 10,# The threshold applied to the cloudScore for Landsat and/or Sentinel-2\n",
    "    performCloudScoreOffset = False,# Set this to False in areas with limited data and/or limited bright cool surfaces\n",
    "    cloudScorePctl = 10, # If performCloudScoreOffset is set to True, this is the percentile of the cloudScores used to see if an area typically has a high cloudScore\n",
    "    zScoreThresh = -1, # The TDOM Z-score threshold for finding dark outliers\n",
    "    shadowSumThresh = 0.35,# The sum of the shadowSumBands has to be below this to be considered dark\n",
    "    contractPixels = 1.5,# Inward buffer pixel radius to get rid of salt and pepper\n",
    "    dilatePixels = 3.5, # Outwoard buffer pixel radius to dilate the cloud shadow mask by\n",
    "\n",
    "    # Image processing\n",
    "    correctIllumination = False, # Method for illuminating hill shadows. This is largely deprecated and not used\n",
    "    correctScale = 250,\n",
    "\n",
    "    # Export parameters\n",
    "   # exportComposites = False,# Whether to export resulting composites exportCompositeCollection\n",
    "   # exportPathRoot = 'projects/disco-glass-413820/assets/users/lcms-training_module-2_composites', #'content/drive/MyDrive/lcms-training_module-2_composites',used this i think #'projects/resolute-future-412019/assets/users/lcms-training_module-2_composites', og directory #'projects/earthengine-public/assets/content/drive/MyDrive/lcms-training_module-2_composites',\n",
    "    exportComposites = True\n",
    "    outputName = 'Landsat-UTKA',\n",
    "    \n",
    "    crs = 'EPSG:4326',\n",
    "    #transform = getImagesLib.common_projections['NLCD_CONUS']['transform'],\n",
    "    transform = None)\n",
    " #   scale = None,\n",
    "  #  overwrite = True,# Whether to overwrite existing composites\n",
    "\n",
    "    #Separate into scenes and composites for subsequent analysis\n",
    "processedScenes = lsAndTs['processedScenes']\n",
    "processedComposites = lsAndTs['processedComposites']\n",
    "\n",
    "#Turn off layers from previous iteration\n",
    "Map.turnOffAllLayers()\n",
    "\n",
    "Map.addLayer(processedComposites.select(['NDVI','NBR']),{'addToLegend':'false'},'Time Series (NBR and NDVI)',True)\n",
    "for year in range(startYear,endYear + 1 ):\n",
    "     t = processedComposites.filter(ee.Filter.calendarRange(year,year,'year')).mosaic()\n",
    "     Map.addLayer(t.float(),getImagesLib.vizParamsFalse,'CloudScore and TDOM added {} {}-{}'.format(year,startJulian,endJulian),'True')\n",
    "\n",
    "Map.turnOnInspector()\n",
    "Map.view()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6738676-193b-409b-b271-ae85bd553bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Turn off layers from previous iteration\n",
    "Map.turnOffAllLayers()\n",
    "\n",
    "Map.addLayer(processedComposites.select(['NDVI','NBR']),{'addToLegend':'false'},'Time Series (NBR and NDVI)',True)\n",
    "for year in range(startYear,endYear + 1 ):\n",
    "     t = processedComposites.filter(ee.Filter.calendarRange(year,year,'year')).mosaic()\n",
    "     Map.addLayer(t.float(),getImagesLib.vizParamsFalse,'CloudScore and TDOM added {} {}-{}'.format(year,startJulian,endJulian),'True')\n",
    "\n",
    "Map.turnOnInspector()\n",
    "Map.view()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0055f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this\n",
    "#  imageForExport = processedComposites.first.clip(roi).unmask(outputNoData,False)\n",
    "# Load an image\n",
    "image = ee.Image(processedComposites.first())\n",
    "\n",
    "# Define the region of interest (ROI)\n",
    "roi = studyArea\n",
    "\n",
    "# Define export parameters\n",
    "export_params = {\n",
    "    'image': image,\n",
    "    'description': 'composite2015',\n",
    "    'folder': 'Composites0220',\n",
    "    'fileNamePrefix': 'composite2015',\n",
    "    'scale': 30,\n",
    "    'region': roi,\n",
    "    'fileFormat': 'GeoTIFF'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = studyArea\n",
    "#Make sure image is clipped to roi in case it's a multi-part polygon\n",
    "#imageForExport = processedComposites.clip(roi).unmask(outputNoData,False)\n",
    "clipped_collection = processedComposites.map(lambda image: image.clip(studyArea))\n",
    "clipped_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportToDriveWrapper(imageForExport,outputName,driveFolderName,roi,scale= None,crs = 4326,transform = None,outputNoData = -32768):\n",
    "  outputName = outputName.replace(\"/\\s+/g\",'-')#Get rid of any spaces\n",
    "\n",
    "  #Pull geometry if feature or featureCollection\n",
    "  try:\n",
    "    roi = studyArea\n",
    "  except Exception as e:\n",
    "    x = e\n",
    "\n",
    "  #Make sure image is clipped to roi in case it's a multi-part polygon\n",
    "  imageForExport = clipped_collection.first().unmask(outputNoData,False)\n",
    "\n",
    "  if transform != None and (str(type(transform)) == \"<type 'list'>\" or str(type(transform)) == \"<class 'list'>\"):\n",
    "    transform = str(transform)\n",
    "\n",
    "\n",
    "  #Ensure bounds are in export projection\n",
    "  outRegion = roi.bounds(100,crs)\n",
    "\n",
    "  # Map.addLayer(imageForExport,{},outputName,False)\n",
    "  #t = ee.batch.Export.image.toDrive(imageForExport, outputName, driveFolderName, outputName, None, outRegion, scale, crs, transform, 1e13)\n",
    "  #print('Exporting:',outputName)\n",
    "  #t.start()\n",
    "\n",
    "  t = ee.batch.Export.image.toDrive(imageForExport, outputName, driveFolderName, outputName, None, outRegion, scale, crs, transform, 1e13)\n",
    "  print('Exporting:',outputName)\n",
    "  t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1700cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Map.port = 1986\n",
    "Map.clearMap()\n",
    "\n",
    "#Turn off layers from previous iteration\n",
    "Map.turnOffAllLayers()\n",
    "\n",
    "Map.addLayer(utka_composites.select(['NDVI','NBR']),{'addToLegend':'false'},'Time Series (NBR and NDVI)',True)\n",
    "for year in range(startYear,endYear + 1 ):\n",
    "     t = utka_composites.filter(ee.Filter.calendarRange(year,year,'year')).mosaic()\n",
    "     Map.addLayer(t.float(),getImagesLib.vizParamsFalse,'CloudScore + TDOM {} {}-{}'.format(year,startJulian,endJulian),'True')\n",
    "Map.centerObject(studyArea, 10)\n",
    "Map.addLayer(studyArea, {'color': 'blue'}, 'UTKA Boundary')\n",
    "Map.turnOnInspector()\n",
    "Map.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52f47043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get Processed Landsat: \n",
      "Start date: Jan 01 2015 , End date: Dec 30 2020\n",
      "Applying scale factors for C2 L4 data\n",
      "Applying scale factors for C2 L5 data\n",
      "Defringing L4 and L5\n",
      "Applying scale factors for C2 L8 data\n",
      "Only including SLC On Landsat 7\n",
      "Applying scale factors for C2 L7 data\n",
      "Applying scale factors for C2 L9 data\n",
      "Applying Cloud Score\n",
      "Not computing cloudScore offset\n",
      "Applying Fmask Cloud Mask\n",
      "Applying TDOM Shadow Mask\n",
      "Computing irMean for TDOM\n",
      "Computing irStdDev for TDOM\n",
      "Applying Fmask Shadow Mask\n",
      "Adding layer: CS and TDOM UTKA 2015 1-365\n",
      "Adding layer: CS and TDOM UTKA 2016 1-365\n",
      "Adding layer: CS and TDOM UTKA 2017 1-365\n",
      "Adding layer: CS and TDOM UTKA 2018 1-365\n",
      "Adding layer: CS and TDOM UTKA 2019 1-365\n",
      "Adding layer: CS and TDOM UTKA 2020 1-365\n",
      "Starting webmap\n",
      "Using default refresh token for geeView\n",
      "Local web server at: http://localhost:1990/geeView/ already serving.\n",
      "cwd /Users/jessieeastburn/Library/CloudStorage/OneDrive-UniversityofUtah/URSA_Work/TS2/PJ_TimeSeries\n",
      "geeView URL: http://localhost:1990/geeView/?projectID=None&accessToken=ya29.a0AfB_byBfJfDlRYVzEEQuvzafg72lQUvvVGTL7IeWNeW5A2uDAEPdFV7bIRXDn64DrtoZwhTlJY3CKcCN4VJQPYUowMYNwmtFmHBi093kq90EYRzB9hxkB_ar07mL-6lbgKRwDO7fTka2fx215Ogg3gEgfH00L2gQYksdGQaCgYKAWQSARISFQHGX2Mi1mpaxn8NXyG3mk3eiGJosg0173\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"525px\"\n",
       "            src=\"http://localhost:1990/geeView/?projectID=None&accessToken=ya29.a0AfB_byBfJfDlRYVzEEQuvzafg72lQUvvVGTL7IeWNeW5A2uDAEPdFV7bIRXDn64DrtoZwhTlJY3CKcCN4VJQPYUowMYNwmtFmHBi093kq90EYRzB9hxkB_ar07mL-6lbgKRwDO7fTka2fx215Ogg3gEgfH00L2gQYksdGQaCgYKAWQSARISFQHGX2Mi1mpaxn8NXyG3mk3eiGJosg0173\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x112de5820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "::1 - - [20/Feb/2024 16:34:53] \"GET /geeView/?projectID=None&accessToken=ya29.a0AfB_byBfJfDlRYVzEEQuvzafg72lQUvvVGTL7IeWNeW5A2uDAEPdFV7bIRXDn64DrtoZwhTlJY3CKcCN4VJQPYUowMYNwmtFmHBi093kq90EYRzB9hxkB_ar07mL-6lbgKRwDO7fTka2fx215Ogg3gEgfH00L2gQYksdGQaCgYKAWQSARISFQHGX2Mi1mpaxn8NXyG3mk3eiGJosg0173 HTTP/1.1\" 200 -\n",
      "::1 - - [20/Feb/2024 16:34:53] \"GET /geeView/src/gee/gee-run/runGeeViz.js HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Run get images, set parameters manually, and export\n",
    "lsAndTs = getImagesLib.getLandsatWrapper(\\\n",
    "\n",
    "    # Study area and time\n",
    "    studyArea = studyArea,\n",
    "    startYear = 2015,\n",
    "    endYear = 2020,\n",
    "    startJulian = 1,\n",
    "    endJulian = 365,\n",
    "\n",
    "    # Moving window options\n",
    "    timebuffer =  0,# If multi-year moving window is needed, use timebuffer > 0 (e.g. timebuffer = 1 will result in a 3 year moving window)\n",
    "    weights =  [1],# To compliment the timebuffer, set weights for each year of the moving window. This enables the center year to have more weight (e.g. [1,3,1] would weight the center year if timebuffer = 1 3x over the buffer years)\n",
    "\n",
    "    # Composite methods and input imagery\n",
    "    compositingMethod = 'medoid', # Specify median or medoid. Medoid allows for storing only the spectral and ancillary bands without indices\n",
    "    toaOrSR = 'SR', # It is advised to only use TOA when combining Landsat and Sentinel-2 since the Sentinel-2 SR data in GEE are terrain-corrected and Landsat are not\n",
    "    includeSLCOffL7 = False, # Whether to include Landsat 7 after May 2003. Scanline artifacts can be found in composites when True\n",
    "    defringeL5 = True, # Whether to get rid of fringe edges found mostly on Landsat 4 and 5\n",
    "    landsatCollectionVersion = 'C2', # To use Collection 1 or 2. Only use C1 if doing legacy work prior to 2022\n",
    "\n",
    "    # Cloud and shadow masking\n",
    "    # There will be a parameter for applying CloudScore+ to Sentinel-2 provided once it is available for all S2 data\n",
    "    applyCloudScore = True, # We use this since fMask struggles for cloud masking\n",
    "    applyTDOM = True, # We use TDOM for Landsat since the fMask cloud shadow masking method struggles a lot\n",
    "    applyFmaskCloudMask = True,\n",
    "    applyFmaskCloudShadowMask = True,\n",
    "    applyFmaskSnowMask = False,\n",
    "    cloudScoreThresh = 10,# The threshold applied to the cloudScore for Landsat and/or Sentinel-2\n",
    "    performCloudScoreOffset = False,# Set this to False in areas with limited data and/or limited bright cool surfaces\n",
    "    cloudScorePctl = 10, # If performCloudScoreOffset is set to True, this is the percentile of the cloudScores used to see if an area typically has a high cloudScore\n",
    "    zScoreThresh = -1, # The TDOM Z-score threshold for finding dark outliers\n",
    "    shadowSumThresh = 0.35,# The sum of the shadowSumBands has to be below this to be considered dark\n",
    "    contractPixels = 1.5,# Inward buffer pixel radius to get rid of salt and pepper\n",
    "    dilatePixels = 3.5, # Outwoard buffer pixel radius to dilate the cloud shadow mask by\n",
    "\n",
    "    # Image processing\n",
    "    correctIllumination = False, # Method for illuminating hill shadows. This is largely deprecated and not used\n",
    "    correctScale = 250,\n",
    "\n",
    "    # Export parameters\n",
    "   # exportComposites = False,# Whether to export resulting composites exportCompositeCollection\n",
    "   # exportPathRoot = 'projects/disco-glass-413820/assets/users/lcms-training_module-2_composites', #'content/drive/MyDrive/lcms-training_module-2_composites',used this i think #'projects/resolute-future-412019/assets/users/lcms-training_module-2_composites', og directory #'projects/earthengine-public/assets/content/drive/MyDrive/lcms-training_module-2_composites',\n",
    "    exportComposites = False,\n",
    "    #outputName = 'Landsat-UTKA',\n",
    "    \n",
    "    crs = 'EPSG:4326',\n",
    "    #transform = getImagesLib.common_projections['NLCD_CONUS']['transform'],\n",
    "    transform = None)\n",
    " #  scale = None,\n",
    "  #  overwrite = True,# Whether to overwrite existing composites\n",
    "\n",
    "    #Separate into scenes and composites for subsequent analysis\n",
    "processedScenes = lsAndTs['processedScenes']\n",
    "processedComposites = lsAndTs['processedComposites']\n",
    "\n",
    "#clear map\n",
    "Map.clearMap()\n",
    "#Turn off layers from previous iteration\n",
    "Map.turnOffAllLayers()\n",
    "\n",
    "#Map.addLayer(processedComposites.select(['NDVI','NBR']),{'addToLegend':'false'},'Time Series (NBR and NDVI)',True)\n",
    "for year in range(startYear,endYear + 1 ):\n",
    "     t = processedComposites.filter(ee.Filter.calendarRange(year,year,'year')).mosaic()\n",
    "     Map.addLayer(t.float(),getImagesLib.vizParamsFalse,'CS and TDOM UTKA {} {}-{}'.format(year,startJulian,endJulian),'True')\n",
    "\n",
    "Map.turnOnInspector()\n",
    "Map.view()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd56df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_collection = processedComposites.map(lambda image: image.clip(studyArea))\n",
    "image1 = clipped_collection.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64a2eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USed to export images. \n",
    "\n",
    "def exportToDriveWrapper(imageForExport,outputName,driveFolderName,roi,scale= None,crs = 4326,transform = None,outputNoData = -32768):\n",
    "  outputName = outputName.replace(\"/\\s+/g\",'-')#Get rid of any spaces\n",
    "\n",
    "  #Pull geometry if feature or featureCollection\n",
    "  try:\n",
    "    roi = studyArea\n",
    "  except Exception as e:\n",
    "    x = e\n",
    "\n",
    "  #Make sure image is clipped to roi in case it's a multi-part polygon\n",
    "  imageForExport = clipped_collection.first().unmask(outputNoData,False)\n",
    "  outputName = 'utka2015'\n",
    "  driveFolderName = 'Composites0220'\n",
    "\n",
    "  if transform != None and (str(type(transform)) == \"<type 'list'>\" or str(type(transform)) == \"<class 'list'>\"):\n",
    "    transform = str(transform)\n",
    "\n",
    "\n",
    "  #Ensure bounds are in export projection\n",
    "  outRegion = roi.bounds(100,crs)\n",
    "\n",
    "  # Map.addLayer(imageForExport,{},outputName,False)\n",
    "  #t = ee.batch.Export.image.toDrive(imageForExport, outputName, driveFolderName, outputName, None, outRegion, scale, crs, transform, 1e13)\n",
    "  #print('Exporting:',outputName)\n",
    "  #t.start()\n",
    "\n",
    "  t = ee.batch.Export.image.toDrive(imageForExport, outputName, driveFolderName, outputName, None, outRegion, scale, crs, transform, 1e13)\n",
    "  print('Exporting:',outputName)\n",
    "  t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run for each image\n",
    "\n",
    "roi = studyArea\n",
    "\n",
    "def exportToDriveWrapper(imageForExport, outputName, driveFolderName, roi, scale=None, crs='EPSG:4326', transform=None, outputNoData=-32768):\n",
    "    outputName = outputName.replace(\"/\\s+/g\", '-')  # Get rid of any spaces\n",
    "\n",
    "    # Ensure bounds are in export projection\n",
    "    outRegion = roi.bounds(100, crs)\n",
    "\n",
    "    # Export the image to Google Drive\n",
    "    t = ee.batch.Export.image.toDrive(imageForExport, outputName, driveFolderName, outputName, None, outRegion, scale, crs, transform, 1e13)\n",
    "    print('Exporting:', outputName)\n",
    "    t.start()\n",
    "\n",
    "# Example usage\n",
    "for image in clipped_collection.getInfo()['features']:\n",
    "    image_id = image['year']\n",
    "    output_name = image_id.replace(\"/\", \"_\")\n",
    "    exportToDriveWrapper(ee.Image(image_id), output_name, 'Composites0220', roi, scale=10, crs='EPSG:4326', transform=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e71d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_collection.getInfo()['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508b7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_collection = processedComposites.map(lambda image: image.clip(studyArea))\n",
    "\n",
    "\n",
    "def exportToDriveWrapper(imageForExport,outputName,driveFolderName,roi,scale= None,crs = 4326,transform = None,outputNoData = -32768):\n",
    "  outputName = outputName.replace(\"/\\s+/g\",'-')#Get rid of any spaces\n",
    "\n",
    "  #Pull geometry if feature or featureCollection\n",
    "  try:\n",
    "    roi = studyArea\n",
    "  except Exception as e:\n",
    "    x = e\n",
    "\n",
    "  #Make sure image is clipped to roi in case it's a multi-part polygon\n",
    "  imageForExport = clipped_collection.first().unmask(outputNoData,False)\n",
    "\n",
    "  if transform != None and (str(type(transform)) == \"<type 'list'>\" or str(type(transform)) == \"<class 'list'>\"):\n",
    "    transform = str(transform)\n",
    "\n",
    "\n",
    "  #Ensure bounds are in export projection\n",
    "  outRegion = roi.bounds(100,crs)\n",
    "\n",
    "  # Map.addLayer(imageForExport,{},outputName,False)\n",
    "  #t = ee.batch.Export.image.toDrive(imageForExport, outputName, driveFolderName, outputName, None, outRegion, scale, crs, transform, 1e13)\n",
    "  #print('Exporting:',outputName)\n",
    "  #t.start()\n",
    "\n",
    "  t = ee.batch.Export.image.toDrive(imageForExport, outputName, driveFolderName, outputName, None, outRegion, scale, crs, transform, 1e13)\n",
    "  print('Exporting:',outputName)\n",
    "  t.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
